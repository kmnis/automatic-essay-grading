{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be65100d",
   "metadata": {},
   "source": [
    "### Phase 2 - Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd0d2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/kshitijmittal/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kshitijmittal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/kshitijmittal/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kshitijmittal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kshitijmittal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b30e49de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>cleaned_tokenize_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['think', 'students', 'would', 'benefit', 'lea...</td>\n",
       "      <td>['think', 'student', 'would', 'benefit', 'lear...</td>\n",
       "      <td>18</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['problem', 'change', 'let', 'best', 'matter',...</td>\n",
       "      <td>['problem', 'change', 'let', 'best', 'matter',...</td>\n",
       "      <td>14</td>\n",
       "      <td>38.071429</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['dear', 'principal', 'change', 'school', 'pol...</td>\n",
       "      <td>['dear', 'principal', 'change', 'school', 'pol...</td>\n",
       "      <td>19</td>\n",
       "      <td>16.842105</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['best', 'time', 'life', 'become', 'agree', 'g...</td>\n",
       "      <td>['best', 'time', 'life', 'become', 'agree', 'g...</td>\n",
       "      <td>36</td>\n",
       "      <td>20.222222</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['small', 'act', 'kindness', 'impact', 'people...</td>\n",
       "      <td>['small', 'act', 'kindness', 'impact', 'people...</td>\n",
       "      <td>3</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>FFD29828A873</td>\n",
       "      <td>I believe using cellphones in class for educat...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['believe', 'using', 'cellphones', 'class', 'e...</td>\n",
       "      <td>['believe', 'use', 'cellphone', 'class', 'educ...</td>\n",
       "      <td>6</td>\n",
       "      <td>29.833333</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>FFD9A83B0849</td>\n",
       "      <td>Working alone, students do not have to argue w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['working', 'alone', 'students', 'argue', 'dec...</td>\n",
       "      <td>['work', 'alone', 'student', 'argue', 'decissi...</td>\n",
       "      <td>16</td>\n",
       "      <td>29.062500</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>FFDC4011AC9C</td>\n",
       "      <td>\"A problem is a chance for you to do your best...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['problem', 'chance', 'best', 'think', 'quote'...</td>\n",
       "      <td>['problem', 'chance', 'best', 'think', 'quote'...</td>\n",
       "      <td>8</td>\n",
       "      <td>32.125000</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>FFE16D704B16</td>\n",
       "      <td>Many people disagree with Albert Schweitzer's ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['many', 'people', 'disagree', 'albert', 'schw...</td>\n",
       "      <td>['many', 'people', 'disagree', 'albert', 'schw...</td>\n",
       "      <td>21</td>\n",
       "      <td>24.285714</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>FFED00D6E0BD</td>\n",
       "      <td>Do you think that failure is the main thing fo...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>['think', 'failure', 'main', 'thing', 'people'...</td>\n",
       "      <td>['think', 'failure', 'main', 'thing', 'people'...</td>\n",
       "      <td>10</td>\n",
       "      <td>63.800000</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3911 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           text_id                                          full_text  \\\n",
       "0     0016926B079C  I think that students would benefit from learn...   \n",
       "1     0022683E9EA5  When a problem is a change you have to let it ...   \n",
       "2     00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n",
       "3     003885A45F42  The best time in life is when you become yours...   \n",
       "4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n",
       "...            ...                                                ...   \n",
       "3906  FFD29828A873  I believe using cellphones in class for educat...   \n",
       "3907  FFD9A83B0849  Working alone, students do not have to argue w...   \n",
       "3908  FFDC4011AC9C  \"A problem is a chance for you to do your best...   \n",
       "3909  FFE16D704B16  Many people disagree with Albert Schweitzer's ...   \n",
       "3910  FFED00D6E0BD  Do you think that failure is the main thing fo...   \n",
       "\n",
       "      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \\\n",
       "0          3.5     3.5         3.0          3.0      4.0          3.0   \n",
       "1          2.5     2.5         3.0          2.0      2.0          2.5   \n",
       "2          3.0     3.5         3.0          3.0      3.0          2.5   \n",
       "3          4.5     4.5         4.5          4.5      4.0          5.0   \n",
       "4          2.5     3.0         3.0          3.0      2.5          2.5   \n",
       "...        ...     ...         ...          ...      ...          ...   \n",
       "3906       2.5     3.0         3.0          3.5      2.5          2.5   \n",
       "3907       4.0     4.0         4.0          4.0      3.5          3.0   \n",
       "3908       2.5     3.0         3.0          3.0      3.5          3.0   \n",
       "3909       4.0     4.5         4.5          4.0      4.5          4.5   \n",
       "3910       3.5     2.5         3.5          3.0      3.0          3.5   \n",
       "\n",
       "                                  cleaned_tokenize_text  \\\n",
       "0     ['think', 'students', 'would', 'benefit', 'lea...   \n",
       "1     ['problem', 'change', 'let', 'best', 'matter',...   \n",
       "2     ['dear', 'principal', 'change', 'school', 'pol...   \n",
       "3     ['best', 'time', 'life', 'become', 'agree', 'g...   \n",
       "4     ['small', 'act', 'kindness', 'impact', 'people...   \n",
       "...                                                 ...   \n",
       "3906  ['believe', 'using', 'cellphones', 'class', 'e...   \n",
       "3907  ['working', 'alone', 'students', 'argue', 'dec...   \n",
       "3908  ['problem', 'chance', 'best', 'think', 'quote'...   \n",
       "3909  ['many', 'people', 'disagree', 'albert', 'schw...   \n",
       "3910  ['think', 'failure', 'main', 'thing', 'people'...   \n",
       "\n",
       "                                        lemmatized_text  sent_count  \\\n",
       "0     ['think', 'student', 'would', 'benefit', 'lear...          18   \n",
       "1     ['problem', 'change', 'let', 'best', 'matter',...          14   \n",
       "2     ['dear', 'principal', 'change', 'school', 'pol...          19   \n",
       "3     ['best', 'time', 'life', 'become', 'agree', 'g...          36   \n",
       "4     ['small', 'act', 'kindness', 'impact', 'people...           3   \n",
       "...                                                 ...         ...   \n",
       "3906  ['believe', 'use', 'cellphone', 'class', 'educ...           6   \n",
       "3907  ['work', 'alone', 'student', 'argue', 'decissi...          16   \n",
       "3908  ['problem', 'chance', 'best', 'think', 'quote'...           8   \n",
       "3909  ['many', 'people', 'disagree', 'albert', 'schw...          21   \n",
       "3910  ['think', 'failure', 'main', 'thing', 'people'...          10   \n",
       "\n",
       "       sent_len  word_count  \n",
       "0     14.500000         261  \n",
       "1     38.071429         533  \n",
       "2     16.842105         320  \n",
       "3     20.222222         728  \n",
       "4     78.000000         234  \n",
       "...         ...         ...  \n",
       "3906  29.833333         179  \n",
       "3907  29.062500         465  \n",
       "3908  32.125000         257  \n",
       "3909  24.285714         510  \n",
       "3910  63.800000         638  \n",
       "\n",
       "[3911 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_data=pd.read_csv('processed_essays.csv')\n",
    "proc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7464314f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_data['lemmatized_text'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff215c",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfedf057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "#vectorizer.fit(proc_data['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3878c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text=vectorizer.fit_transform(proc_data['lemmatized_text'].apply(lambda x: ''.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d38c23bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectorized = pd.DataFrame(vectorized_text.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d44cd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>021419</th>\n",
       "      <th>03102020</th>\n",
       "      <th>031219</th>\n",
       "      <th>031519</th>\n",
       "      <th>03192019</th>\n",
       "      <th>032019</th>\n",
       "      <th>03202019</th>\n",
       "      <th>0492019</th>\n",
       "      <th>050</th>\n",
       "      <th>0school</th>\n",
       "      <th>...</th>\n",
       "      <th>zere</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zonned</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoology</th>\n",
       "      <th>zore</th>\n",
       "      <th>zurkrbuirg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3911 rows × 18039 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      021419  03102020  031219  031519  03192019  032019  03202019  0492019  \\\n",
       "0          0         0       0       0         0       0         0        0   \n",
       "1          0         0       0       0         0       0         0        0   \n",
       "2          0         0       0       0         0       0         0        0   \n",
       "3          0         0       0       0         0       0         0        0   \n",
       "4          0         0       0       0         0       0         0        0   \n",
       "...      ...       ...     ...     ...       ...     ...       ...      ...   \n",
       "3906       0         0       0       0         0       0         0        0   \n",
       "3907       0         0       0       0         0       0         0        0   \n",
       "3908       0         0       0       0         0       0         0        0   \n",
       "3909       0         0       0       0         0       0         0        0   \n",
       "3910       0         0       0       0         0       0         0        0   \n",
       "\n",
       "      050  0school  ...  zere  zero  zip  zombie  zone  zonned  zoo  zoology  \\\n",
       "0       0        0  ...     0     0    0       0     0       0    0        0   \n",
       "1       0        0  ...     0     0    0       0     0       0    0        0   \n",
       "2       0        0  ...     0     0    0       0     0       0    0        0   \n",
       "3       0        0  ...     0     0    0       0     0       0    0        0   \n",
       "4       0        0  ...     0     0    0       0     0       0    0        0   \n",
       "...   ...      ...  ...   ...   ...  ...     ...   ...     ...  ...      ...   \n",
       "3906    0        0  ...     0     0    0       0     0       0    0        0   \n",
       "3907    0        0  ...     0     0    0       0     0       0    0        0   \n",
       "3908    0        0  ...     0     0    0       0     0       0    0        0   \n",
       "3909    0        0  ...     0     0    0       0     0       0    0        0   \n",
       "3910    0        0  ...     0     0    0       0     0       0    0        0   \n",
       "\n",
       "      zore  zurkrbuirg  \n",
       "0        0           0  \n",
       "1        0           0  \n",
       "2        0           0  \n",
       "3        0           0  \n",
       "4        0           0  \n",
       "...    ...         ...  \n",
       "3906     0           0  \n",
       "3907     0           0  \n",
       "3908     0           0  \n",
       "3909     0           0  \n",
       "3910     0           0  \n",
       "\n",
       "[3911 rows x 18039 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccdf2536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectorized.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe52ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectorized_array = df_vectorized.apply(lambda x: x.values if len(x.values.shape) == 1 else np.concatenate([x.values]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf273de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "                              ...                        \n",
       "3906    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3907    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3908    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3909    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3910    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Length: 3911, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectorized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a13e1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data_2=proc_data.copy()\n",
    "proc_data_2['count_vector']=df_vectorized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52af4d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_vectorized_array = df_vectorized.apply(lambda x: np.hstack(x.values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26951572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>cleaned_tokenize_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>count_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['think', 'students', 'would', 'benefit', 'lea...</td>\n",
       "      <td>['think', 'student', 'would', 'benefit', 'lear...</td>\n",
       "      <td>18</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>261</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['problem', 'change', 'let', 'best', 'matter',...</td>\n",
       "      <td>['problem', 'change', 'let', 'best', 'matter',...</td>\n",
       "      <td>14</td>\n",
       "      <td>38.071429</td>\n",
       "      <td>533</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['dear', 'principal', 'change', 'school', 'pol...</td>\n",
       "      <td>['dear', 'principal', 'change', 'school', 'pol...</td>\n",
       "      <td>19</td>\n",
       "      <td>16.842105</td>\n",
       "      <td>320</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['best', 'time', 'life', 'become', 'agree', 'g...</td>\n",
       "      <td>['best', 'time', 'life', 'become', 'agree', 'g...</td>\n",
       "      <td>36</td>\n",
       "      <td>20.222222</td>\n",
       "      <td>728</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['small', 'act', 'kindness', 'impact', 'people...</td>\n",
       "      <td>['small', 'act', 'kindness', 'impact', 'people...</td>\n",
       "      <td>3</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>234</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>FFD29828A873</td>\n",
       "      <td>I believe using cellphones in class for educat...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['believe', 'using', 'cellphones', 'class', 'e...</td>\n",
       "      <td>['believe', 'use', 'cellphone', 'class', 'educ...</td>\n",
       "      <td>6</td>\n",
       "      <td>29.833333</td>\n",
       "      <td>179</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>FFD9A83B0849</td>\n",
       "      <td>Working alone, students do not have to argue w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['working', 'alone', 'students', 'argue', 'dec...</td>\n",
       "      <td>['work', 'alone', 'student', 'argue', 'decissi...</td>\n",
       "      <td>16</td>\n",
       "      <td>29.062500</td>\n",
       "      <td>465</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>FFDC4011AC9C</td>\n",
       "      <td>\"A problem is a chance for you to do your best...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['problem', 'chance', 'best', 'think', 'quote'...</td>\n",
       "      <td>['problem', 'chance', 'best', 'think', 'quote'...</td>\n",
       "      <td>8</td>\n",
       "      <td>32.125000</td>\n",
       "      <td>257</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>FFE16D704B16</td>\n",
       "      <td>Many people disagree with Albert Schweitzer's ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['many', 'people', 'disagree', 'albert', 'schw...</td>\n",
       "      <td>['many', 'people', 'disagree', 'albert', 'schw...</td>\n",
       "      <td>21</td>\n",
       "      <td>24.285714</td>\n",
       "      <td>510</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>FFED00D6E0BD</td>\n",
       "      <td>Do you think that failure is the main thing fo...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>['think', 'failure', 'main', 'thing', 'people'...</td>\n",
       "      <td>['think', 'failure', 'main', 'thing', 'people'...</td>\n",
       "      <td>10</td>\n",
       "      <td>63.800000</td>\n",
       "      <td>638</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3911 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           text_id                                          full_text  \\\n",
       "0     0016926B079C  I think that students would benefit from learn...   \n",
       "1     0022683E9EA5  When a problem is a change you have to let it ...   \n",
       "2     00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n",
       "3     003885A45F42  The best time in life is when you become yours...   \n",
       "4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n",
       "...            ...                                                ...   \n",
       "3906  FFD29828A873  I believe using cellphones in class for educat...   \n",
       "3907  FFD9A83B0849  Working alone, students do not have to argue w...   \n",
       "3908  FFDC4011AC9C  \"A problem is a chance for you to do your best...   \n",
       "3909  FFE16D704B16  Many people disagree with Albert Schweitzer's ...   \n",
       "3910  FFED00D6E0BD  Do you think that failure is the main thing fo...   \n",
       "\n",
       "      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \\\n",
       "0          3.5     3.5         3.0          3.0      4.0          3.0   \n",
       "1          2.5     2.5         3.0          2.0      2.0          2.5   \n",
       "2          3.0     3.5         3.0          3.0      3.0          2.5   \n",
       "3          4.5     4.5         4.5          4.5      4.0          5.0   \n",
       "4          2.5     3.0         3.0          3.0      2.5          2.5   \n",
       "...        ...     ...         ...          ...      ...          ...   \n",
       "3906       2.5     3.0         3.0          3.5      2.5          2.5   \n",
       "3907       4.0     4.0         4.0          4.0      3.5          3.0   \n",
       "3908       2.5     3.0         3.0          3.0      3.5          3.0   \n",
       "3909       4.0     4.5         4.5          4.0      4.5          4.5   \n",
       "3910       3.5     2.5         3.5          3.0      3.0          3.5   \n",
       "\n",
       "                                  cleaned_tokenize_text  \\\n",
       "0     ['think', 'students', 'would', 'benefit', 'lea...   \n",
       "1     ['problem', 'change', 'let', 'best', 'matter',...   \n",
       "2     ['dear', 'principal', 'change', 'school', 'pol...   \n",
       "3     ['best', 'time', 'life', 'become', 'agree', 'g...   \n",
       "4     ['small', 'act', 'kindness', 'impact', 'people...   \n",
       "...                                                 ...   \n",
       "3906  ['believe', 'using', 'cellphones', 'class', 'e...   \n",
       "3907  ['working', 'alone', 'students', 'argue', 'dec...   \n",
       "3908  ['problem', 'chance', 'best', 'think', 'quote'...   \n",
       "3909  ['many', 'people', 'disagree', 'albert', 'schw...   \n",
       "3910  ['think', 'failure', 'main', 'thing', 'people'...   \n",
       "\n",
       "                                        lemmatized_text  sent_count  \\\n",
       "0     ['think', 'student', 'would', 'benefit', 'lear...          18   \n",
       "1     ['problem', 'change', 'let', 'best', 'matter',...          14   \n",
       "2     ['dear', 'principal', 'change', 'school', 'pol...          19   \n",
       "3     ['best', 'time', 'life', 'become', 'agree', 'g...          36   \n",
       "4     ['small', 'act', 'kindness', 'impact', 'people...           3   \n",
       "...                                                 ...         ...   \n",
       "3906  ['believe', 'use', 'cellphone', 'class', 'educ...           6   \n",
       "3907  ['work', 'alone', 'student', 'argue', 'decissi...          16   \n",
       "3908  ['problem', 'chance', 'best', 'think', 'quote'...           8   \n",
       "3909  ['many', 'people', 'disagree', 'albert', 'schw...          21   \n",
       "3910  ['think', 'failure', 'main', 'thing', 'people'...          10   \n",
       "\n",
       "       sent_len  word_count                                       count_vector  \n",
       "0     14.500000         261  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     38.071429         533  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     16.842105         320  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     20.222222         728  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     78.000000         234  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...         ...         ...                                                ...  \n",
       "3906  29.833333         179  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3907  29.062500         465  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3908  32.125000         257  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3909  24.285714         510  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3910  63.800000         638  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[3911 rows x 14 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893b9323",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abec60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(data):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,2),min_df=10,max_features=100)\n",
    "    vec_text = vectorizer.fit_transform(data)\n",
    "    X = pd.DataFrame.sparse.from_spmatrix(vec_text)\n",
    "    X.columns = vectorizer.get_feature_names_out().tolist()\n",
    "    X=X.reset_index(drop=True)\n",
    "    data=data.reset_index(drop=True)\n",
    "    newdata = pd.concat([data, X],axis=1)\n",
    "    del X\n",
    "    gc.collect()\n",
    "    return newdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69325944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>cleaned_tokenize_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>count_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['think', 'students', 'would', 'benefit', 'lea...</td>\n",
       "      <td>['think', 'student', 'would', 'benefit', 'lear...</td>\n",
       "      <td>18</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>261</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['problem', 'change', 'let', 'best', 'matter',...</td>\n",
       "      <td>['problem', 'change', 'let', 'best', 'matter',...</td>\n",
       "      <td>14</td>\n",
       "      <td>38.071429</td>\n",
       "      <td>533</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['dear', 'principal', 'change', 'school', 'pol...</td>\n",
       "      <td>['dear', 'principal', 'change', 'school', 'pol...</td>\n",
       "      <td>19</td>\n",
       "      <td>16.842105</td>\n",
       "      <td>320</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['best', 'time', 'life', 'become', 'agree', 'g...</td>\n",
       "      <td>['best', 'time', 'life', 'become', 'agree', 'g...</td>\n",
       "      <td>36</td>\n",
       "      <td>20.222222</td>\n",
       "      <td>728</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['small', 'act', 'kindness', 'impact', 'people...</td>\n",
       "      <td>['small', 'act', 'kindness', 'impact', 'people...</td>\n",
       "      <td>3</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>234</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \\\n",
       "0     3.5         3.0          3.0      4.0          3.0   \n",
       "1     2.5         3.0          2.0      2.0          2.5   \n",
       "2     3.5         3.0          3.0      3.0          2.5   \n",
       "3     4.5         4.5          4.5      4.0          5.0   \n",
       "4     3.0         3.0          3.0      2.5          2.5   \n",
       "\n",
       "                               cleaned_tokenize_text  \\\n",
       "0  ['think', 'students', 'would', 'benefit', 'lea...   \n",
       "1  ['problem', 'change', 'let', 'best', 'matter',...   \n",
       "2  ['dear', 'principal', 'change', 'school', 'pol...   \n",
       "3  ['best', 'time', 'life', 'become', 'agree', 'g...   \n",
       "4  ['small', 'act', 'kindness', 'impact', 'people...   \n",
       "\n",
       "                                     lemmatized_text  sent_count   sent_len  \\\n",
       "0  ['think', 'student', 'would', 'benefit', 'lear...          18  14.500000   \n",
       "1  ['problem', 'change', 'let', 'best', 'matter',...          14  38.071429   \n",
       "2  ['dear', 'principal', 'change', 'school', 'pol...          19  16.842105   \n",
       "3  ['best', 'time', 'life', 'become', 'agree', 'g...          36  20.222222   \n",
       "4  ['small', 'act', 'kindness', 'impact', 'people...           3  78.000000   \n",
       "\n",
       "   word_count                                       count_vector  \n",
       "0         261  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1         533  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2         320  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3         728  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4         234  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34a34c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TFIDF_vectorizer = TfidfVectorizer(ngram_range=(1,2),min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a73418ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_text_tfidf=TFIDF_vectorizer.fit_transform(proc_data_2['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "006d41d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectorized_tfid = pd.DataFrame(vec_text_tfidf.toarray())\n",
    "#df_vectorized = pd.DataFrame(vectorized_text.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "16a9f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectorized_tfidf = pd.DataFrame(vec_text_tfidf.toarray())\n",
    "df_vectorized_tfidf.columns = TFIDF_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2f6bfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>11th</th>\n",
       "      <th>2015</th>\n",
       "      <th>2019</th>\n",
       "      <th>4th</th>\n",
       "      <th>5th</th>\n",
       "      <th>6th</th>\n",
       "      <th>7th</th>\n",
       "      <th>7th grade</th>\n",
       "      <th>...</th>\n",
       "      <th>young person</th>\n",
       "      <th>young sibling</th>\n",
       "      <th>young student</th>\n",
       "      <th>youre</th>\n",
       "      <th>youself</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   100  1000  11th  2015  2019  4th  5th  6th  7th  7th grade  ...  \\\n",
       "0  0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0        0.0  ...   \n",
       "1  0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0        0.0  ...   \n",
       "2  0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0        0.0  ...   \n",
       "3  0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0        0.0  ...   \n",
       "4  0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0        0.0  ...   \n",
       "\n",
       "   young person  young sibling  young student  youre  youself  youth  youtube  \\\n",
       "0           0.0            0.0            0.0    0.0      0.0    0.0      0.0   \n",
       "1           0.0            0.0            0.0    0.0      0.0    0.0      0.0   \n",
       "2           0.0            0.0            0.0    0.0      0.0    0.0      0.0   \n",
       "3           0.0            0.0            0.0    0.0      0.0    0.0      0.0   \n",
       "4           0.0            0.0            0.0    0.0      0.0    0.0      0.0   \n",
       "\n",
       "   zero  zone  zoo  \n",
       "0   0.0   0.0  0.0  \n",
       "1   0.0   0.0  0.0  \n",
       "2   0.0   0.0  0.0  \n",
       "3   0.0   0.0  0.0  \n",
       "4   0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 11680 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectorized_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21a32537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectorized_tfidf_array = df_vectorized_tfidf.apply(lambda x: x.values if len(x.values.shape) == 1 else np.concatenate([x.values]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e83c6a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "                              ...                        \n",
       "3906    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3907    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3908    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3909    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3910    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "Length: 3911, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "70c99d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data_3=proc_data_2.copy()\n",
    "proc_data_3['tfidf_vector']=df_vectorized_tfidf_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "542d605b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>cleaned_tokenize_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>count_vector</th>\n",
       "      <th>tfidf_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['think', 'students', 'would', 'benefit', 'lea...</td>\n",
       "      <td>['think', 'student', 'would', 'benefit', 'lear...</td>\n",
       "      <td>18</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>261</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['problem', 'change', 'let', 'best', 'matter',...</td>\n",
       "      <td>['problem', 'change', 'let', 'best', 'matter',...</td>\n",
       "      <td>14</td>\n",
       "      <td>38.071429</td>\n",
       "      <td>533</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['dear', 'principal', 'change', 'school', 'pol...</td>\n",
       "      <td>['dear', 'principal', 'change', 'school', 'pol...</td>\n",
       "      <td>19</td>\n",
       "      <td>16.842105</td>\n",
       "      <td>320</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['best', 'time', 'life', 'become', 'agree', 'g...</td>\n",
       "      <td>['best', 'time', 'life', 'become', 'agree', 'g...</td>\n",
       "      <td>36</td>\n",
       "      <td>20.222222</td>\n",
       "      <td>728</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['small', 'act', 'kindness', 'impact', 'people...</td>\n",
       "      <td>['small', 'act', 'kindness', 'impact', 'people...</td>\n",
       "      <td>3</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>234</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \\\n",
       "0     3.5         3.0          3.0      4.0          3.0   \n",
       "1     2.5         3.0          2.0      2.0          2.5   \n",
       "2     3.5         3.0          3.0      3.0          2.5   \n",
       "3     4.5         4.5          4.5      4.0          5.0   \n",
       "4     3.0         3.0          3.0      2.5          2.5   \n",
       "\n",
       "                               cleaned_tokenize_text  \\\n",
       "0  ['think', 'students', 'would', 'benefit', 'lea...   \n",
       "1  ['problem', 'change', 'let', 'best', 'matter',...   \n",
       "2  ['dear', 'principal', 'change', 'school', 'pol...   \n",
       "3  ['best', 'time', 'life', 'become', 'agree', 'g...   \n",
       "4  ['small', 'act', 'kindness', 'impact', 'people...   \n",
       "\n",
       "                                     lemmatized_text  sent_count   sent_len  \\\n",
       "0  ['think', 'student', 'would', 'benefit', 'lear...          18  14.500000   \n",
       "1  ['problem', 'change', 'let', 'best', 'matter',...          14  38.071429   \n",
       "2  ['dear', 'principal', 'change', 'school', 'pol...          19  16.842105   \n",
       "3  ['best', 'time', 'life', 'become', 'agree', 'g...          36  20.222222   \n",
       "4  ['small', 'act', 'kindness', 'impact', 'people...           3  78.000000   \n",
       "\n",
       "   word_count                                       count_vector  \\\n",
       "0         261  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1         533  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2         320  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3         728  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4         234  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                        tfidf_vector  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_data_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b13eae",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "527dd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install gensim\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "825181f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_model = gensim.models.Word2Vec(proc_data_3['lemmatized_text'], min_count = 1,\n",
    "                              vector_size = 100, window = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d671119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
